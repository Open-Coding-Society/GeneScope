{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: P2 Computing Bias (2025)\n",
    "permalink: /compbias/\n",
    "author: Avika, Gabi, Zoe\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 What is Computing Bias?\n",
    "> **Bias:** An inclination or prejudice in favor of or against a person or a group of people, typically in a way that is unfair.\n",
    "\n",
    "Computing **bias** occurs when computer programs, algorithms, or systems produce results that unfairly favor or disadvantage certain groups. This bias can result from **biased data, flawed design, or unintended consequences** of programming.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aeBLboArW8c?si=No1ZvRCvxdiEmbZB\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "---\n",
    "\n",
    "## 🎥 Example: Netflix Recommendation Bias\n",
    "Netflix provides content recommendations to users through algorithms. However, these algorithms can introduce bias in several ways:  \n",
    "\n",
    "### 🔍 **How Bias Can Occur:**\n",
    "- **Majority Preference Bias:**  \n",
    "  - Recommending mostly popular content, making it hard for less popular or niche content to be discovered.  \n",
    "- **Filtering Bias:**  \n",
    "  - Filtering out content that doesn’t fit a user’s perceived interests based on limited viewing history.  \n",
    "  - For example, if a user primarily watches romantic comedies, Netflix may avoid suggesting documentaries or foreign films, even if the user would enjoy them.  \n",
    "\n",
    "---\n",
    "\n",
    "# 🧐 How Does Computing Bias Happen?\n",
    "Computing bias can occur for various reasons, including:  \n",
    "\n",
    "### 📂 **1. Unrepresentative or Incomplete Data:**  \n",
    "- Algorithms trained on data that **doesn't represent real-world diversity** will produce biased results.  \n",
    "\n",
    "### 📉 **2. Flawed or Biased Data:**  \n",
    "- Historical or existing prejudices reflected in the training data can lead to biased outputs.  \n",
    "\n",
    "### 📝 **3. Data Collection & Labeling:**  \n",
    "- Human annotators may introduce biases due to different cultural or personal biases during the data labeling process.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 **Explicit Data vs. Implicit Data**\n",
    "\n",
    "### 📝 **Explicit Data**\n",
    "**Definition:** Data that the user or programmer **directly provides**.\n",
    "\n",
    "- **Example:** On Netflix, users input personal information such as **name**, **age**, and **preferences**. They can also **rate shows** or **movies**.\n",
    "\n",
    "### 🔍 **Implicit Data**\n",
    "**Definition:** Data that is **inferred** from the user's actions or behavior, not directly provided.\n",
    "\n",
    "- **Example:** Netflix tracks your **viewing history**, **watch time**, and **interactions** with content. This data is then used to **recommend shows and movies** that Netflix thinks you might like.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚖️ **Implications**\n",
    "- **Implicit Data** can lead to reinforcing **bias** by suggesting content based on **past behavior**, potentially **limiting diversity** and preventing users from discovering new genres.\n",
    "- **Explicit Data** is generally more **accurate** but can still be biased if **user input is limited** or influenced by the **design of the platform**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Types of Bias\n",
    "\n",
    "> **🤖 Algorithmic Bias**  \n",
    "- <ins>Algorithmic bias</ins> is bias generated from a repeatable but faulty **computer system** that produces inaccurate results.\n",
    "    - Example: A hiring algorithm at Apple is trained on past employee data but the data shows that male candidates were hired more often than female candidates. Because of this, the system would favor male candidates over female candidates because historical hiring practices were biased toward men.\n",
    "> **📈 Data Bias**  \n",
    "- <ins>Data bias</ins> occurs when the data itself includes bias caused by **incomplete or erroneous information**.\n",
    "    - Example: A healthcare AI model predicts lower disease risk for certain populations. Since the AI model hasn't been introduced to other demographics, it would assume that data should include patients from a specific demographic, and not consider others.\n",
    "> **🧠 Cognitive Bias**  \n",
    "- <ins>Cognitive bias</ins> is when the person unintentionally introduces **their own bias** in the data.\n",
    "    - Example: A researcher conducting a study on social media usage unconsciously selects data that supports their belief that too much screen time leads to lower grades. This is a form of cognitive bias called confirmation bias because the researcher is searching for information to support their beliefs.\n",
    "\n",
    "\n",
    "## Computing Bias 🚀\n",
    "\n",
    "Imagine you are training a facial recognition system to identify people. The system uses a large dataset of images for training, but the dataset is overwhelmingly composed of individuals from one region with a predominantly light skin tone. As a result, the system performs poorly when trying to recognize individuals with darker skin tones or those from different regions, even though it was designed to identify people equally.\n",
    "\n",
    "> What kind of bias does this scenario represent?\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Reveal Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: Data Bias! The dataset used to train the system lacked diversity, which led to biased performance against certain groups.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "Now, imagine you're building an AI-powered loan approval system that learns from past data. The system was trained on historical loan approvals, but the data used for training contains an unequal representation of applicants from different socioeconomic backgrounds. As a result, the system tends to favor applicants from higher-income backgrounds, even though other factors like creditworthiness are more relevant.\n",
    "\n",
    "> What kind of bias does this scenario represent?\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Reveal Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: Algorithmic Bias! The system unintentionally learned to favor applicants from higher-income backgrounds based on historical data, which introduces an unfair advantage.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "Lastly, imagine a tech company that is testing its AI-driven job recommendation system. The system was designed to match candidates with job openings based on their resumes. However, if the system has been trained on resumes from predominantly one gender or age group, it may recommend jobs to applicants based on historical trends, which inadvertently introduces bias towards those groups.\n",
    "\n",
    "> What kind of bias does this scenario represent?\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Reveal Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: Cognitive Bias! The individuals creating and training the system unintentionally introduced their own biases when curating the data or designing the algorithm.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Style for the button */\n",
    "    .button {\n",
    "        padding: 12px 25px;\n",
    "        font-size: 18px;\n",
    "        color: white;\n",
    "        background-color: #4CAF50;\n",
    "        border: none;\n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: all 0.3s ease;\n",
    "        text-align: center;\n",
    "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "\n",
    "    .button:hover {\n",
    "        background-color: #45a049;\n",
    "    }\n",
    "\n",
    "    /* Container for the flip effect */\n",
    "    .flip-container {\n",
    "        perspective: 1000px;\n",
    "        margin: 20px 0;\n",
    "    }\n",
    "\n",
    "    .flipper {\n",
    "        width: 100%;\n",
    "        height: 70px;\n",
    "        transform-style: preserve-3d;\n",
    "        transition: transform 0.6s;\n",
    "        display: flex;\n",
    "        justify-content: center;\n",
    "        align-items: center;\n",
    "    }\n",
    "\n",
    "    /* Initially, the answer side is hidden */\n",
    "    .front, .back {\n",
    "        position: absolute;\n",
    "        backface-visibility: hidden;\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        display: flex;\n",
    "        justify-content: center;\n",
    "        align-items: center;\n",
    "        font-size: 16px;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        padding: 15px;\n",
    "        border-radius: 8px;\n",
    "    }\n",
    "\n",
    "    /* Front of the card (button) */\n",
    "    .front {\n",
    "        background-color: #007BFF;\n",
    "        color: white;\n",
    "        border: 2px solid #0056b3;\n",
    "    }\n",
    "\n",
    "    /* Back of the card (answer) */\n",
    "    .back {\n",
    "        background-color: #28a745;\n",
    "        color: white;\n",
    "        transform: rotateY(180deg);\n",
    "    }\n",
    "\n",
    "    /* Flipped state */\n",
    "    .flipped .flipper {\n",
    "        transform: rotateY(180deg);\n",
    "    }\n",
    "\n",
    "    /* Card container for question text */\n",
    "    .question-container {\n",
    "        margin: 20px;\n",
    "        font-size: 18px;\n",
    "        color: #333;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        line-height: 1.6;\n",
    "        font-weight: 500;\n",
    "    }\n",
    "\n",
    "    /* Heading styling */\n",
    "    .heading {\n",
    "        font-size: 24px;\n",
    "        color: #007BFF;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "## Intentional Bias vs Unintentional Bias\n",
    "\n",
    "> **Intentional Bias:** The deliberate introduction of prejudice or unfairness into algorithms or systems, often by individuals or organizations, to achieve a specific outcome or advantage.\n",
    "\n",
    "Example: Imagine a company using a hiring algorithm to screen job applicants.\n",
    "- **Goal of the algorithm:** Select the most qualified candidates based on their resumes and experience.\n",
    "- However, the people who create this algorithm might intentionally (or unknowingly) include factors that are biased toward certain groups.\n",
    "\n",
    "For example, if the algorithm is designed to prioritize resumes with certain words or experiences that are more common among a specific gender or ethnic group, it might unfairly favor candidates from that group over others.\n",
    "\n",
    "Also, if the algorithm gives extra weight to leadership positions in high-profile companies that are predominantly male or white, it may unintentionally (but intentionally by the developers) disadvantage women or people of color who have the same qualifications but worked in different environments.\n",
    "\n",
    "> **Unintentional Bias:** Occurs when algorithms, often trained on flawed or incomplete data, produce results that unfairly discriminate against certain groups.\n",
    "\n",
    "Example: A facial recognition software.\n",
    "- **Goal of the program:** Designed to identify people based on their facial features.\n",
    "- However, if the software is trained using a large dataset of photos primarily of one race, it can have trouble identifying individuals who look different.\n",
    "\n",
    "For example, if the software is trained using pictures of people but the majority of those photos are of lighter-skinned individuals, the system may have trouble accurately recognizing people with darker skin tones.\n",
    "\n",
    "This unintentional bias happens because the developers didn’t purposefully choose to exclude people with darker skin, but because the dataset they used happened to be unbalanced.\n",
    "\n",
    "As a result, the system works better for lighter-skinned people and struggles with darker-skinned people, even though the goal is to treat everyone equally.\n",
    "\n",
    "## Question 1: Intentional Bias in Algorithms\n",
    "\n",
    "<div class=\"question-container\">\n",
    "    Imagine a social media platform uses an algorithm to recommend content to users. The algorithm prioritizes content from popular influencers, who tend to be young, white, and from a specific socioeconomic background. Is this an example of intentional or unintentional bias? Why?\n",
    "</div>\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Reveal Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: Intentional Bias! The algorithm deliberately favors influencers with a specific background, thus prioritizing content from a certain group over others.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "## Question 2: Unintentional Bias in Machine Learning\n",
    "\n",
    "<div class=\"question-container\">\n",
    "    Imagine a company develops a system to filter online reviews. The system is trained on past reviews that mostly come from customers in urban areas, who tend to have different preferences compared to rural customers. As a result, the system struggles to fairly assess reviews from rural customers. Is this intentional or unintentional bias?\n",
    "</div>\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Reveal Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: Unintentional Bias! The dataset is unbalanced, leading the system to perform better for urban customers while struggling with rural customers.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "    function flipCard() {\n",
    "        const flipContainer = event.target.closest('.flip-container');\n",
    "        flipContainer.classList.toggle('flipped');\n",
    "    }\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 **Computing Bias - Homework Questions**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Multiple-Choice Questions**  \n",
    "\n",
    "**1. What is computing bias?**  \n",
    "A. A mistake in the code causing a program to crash.  \n",
    "B. A program or algorithm producing results that favor or disadvantage certain groups.  \n",
    "C. A technical error in hardware causing malfunctions.  \n",
    "D. The act of manually inputting incorrect data.  \n",
    "\n",
    "---\n",
    "\n",
    "**2. What is the primary cause of bias in computing systems?**  \n",
    "A. Poor internet connection.  \n",
    "B. Unrepresentative or incomplete data used to train algorithms.  \n",
    "C. Efficient programming techniques.  \n",
    "D. Increased processing power.  \n",
    "\n",
    "---\n",
    "\n",
    "**3. Which of the following is an example of implicit data collection?**  \n",
    "A. Filling out a survey about your favorite movies.  \n",
    "B. Clicking “like” on a specific genre on Netflix.  \n",
    "C. Netflix tracking your watch history and suggesting similar shows.  \n",
    "D. Manually selecting your preferred language on a streaming platform.  \n",
    "\n",
    "---\n",
    "\n",
    "**4. What is a common issue when algorithms are trained on biased datasets?**  \n",
    "A. They run faster.  \n",
    "B. They become more accurate.  \n",
    "C. They can reinforce existing societal biases.  \n",
    "D. They use less memory.  \n",
    "\n",
    "---\n",
    "\n",
    "**5. Which of the following could help reduce computing bias in recommendation systems?**  \n",
    "A. Ignoring user preferences.  \n",
    "B. Only using data from popular sources.  \n",
    "C. Using diverse and representative training data.  \n",
    "D. Deleting all user data.  \n",
    "\n",
    "---\n",
    "\n",
    "## ✍️ **Short-Answer Question**  \n",
    "\n",
    "**Explain the difference between implicit and explicit data. Provide an example of each.**  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
